# LocaLense V2 - Project Structure & Working Documentation

**Last Updated:** December 3, 2025  
**Project Name:** Vantage (formerly LocaLense)  
**Type:** AI-Powered Semantic Document Search & Chat Assistant

---

## ğŸ“‹ Table of Contents

1. [Project Overview](#project-overview)
2. [Complete File Structure](#complete-file-structure)
3. [Architecture Overview](#architecture-overview)
4. [How The System Works](#how-the-system-works)
5. [Backend Components](#backend-components)
6. [Frontend Components](#frontend-components)
7. [Data Flow](#data-flow)
8. [Configuration](#configuration)
9. [Database Schema](#database-schema)
10. [Development Workflow](#development-workflow)

---

## ğŸ¯ Project Overview

**Vantage** is a sophisticated AI-powered document search and management system that combines semantic search, RAG (Retrieval-Augmented Generation), and multi-agent conversational AI to help users find and interact with their documents through natural language.

### Core Technologies
- **Frontend:** React 18 + Vite
- **Backend:** FastAPI (Python)
- **Vector Database:** OpenSearch
- **LLM:** Ollama (qwen2.5:7b for text, qwen2.5vl for vision)
- **Embeddings:** nomic-embed-text (768 dimensions)
- **Storage:** SQLite (users, conversations, memory)
- **File Monitoring:** Watchdog

### Key Features
âœ… Password-protected multi-user authentication  
âœ… Document indexing (PDF, DOCX, XLSX, images, text)  
âœ… Semantic + hybrid search (vector + BM25)  
âœ… Conversational UI with SSE streaming  
âœ… Document attachment for focused queries  
âœ… Real-time file watching for auto-indexing  
âœ… Multi-agent system (orchestrator, search, analysis, clarification)  
âœ… Memory system (session, user profile, procedural)  
âœ… Dark mode UI  

---

## ğŸ“ Complete File Structure

```
LocaLense_V2/
â”‚
â”œâ”€â”€ ğŸ“„ Root Configuration Files
â”‚   â”œâ”€â”€ config.yaml                    # Main configuration (Ollama, OpenSearch, agents, memory)
â”‚   â”œâ”€â”€ requirements.txt               # Python dependencies
â”‚   â”œâ”€â”€ docker-compose.yml             # Docker setup for OpenSearch
â”‚   â”œâ”€â”€ run.bat                        # Windows startup script
â”‚   â”œâ”€â”€ run.sh                         # Linux/Mac startup script
â”‚   â”œâ”€â”€ app.py                         # Legacy entry point (still functional)
â”‚   â”œâ”€â”€ locallens_conversations.db     # SQLite DB for conversations
â”‚   â”œâ”€â”€ locallens_memory.db            # SQLite DB for memory system
â”‚   â””â”€â”€ locallens_users.json           # User authentication data
â”‚
â”œâ”€â”€ ğŸ“– Documentation
â”‚   â”œâ”€â”€ README.md                      # Main project documentation
â”‚   â”œâ”€â”€ ARCHITECTURE.md                # Detailed system architecture
â”‚   â”œâ”€â”€ QUICKSTART.md                  # Quick setup guide
â”‚   â”œâ”€â”€ LINKEDIN_POST.md               # Marketing content
â”‚   â””â”€â”€ working.md                     # This file (project structure)
â”‚
â”œâ”€â”€ ğŸ› ï¸ Utility Scripts
â”‚   â”œâ”€â”€ delete_index.py                # Delete OpenSearch index
â”‚   â”œâ”€â”€ init_memory.py                 # Initialize memory database
â”‚   â”œâ”€â”€ test_auth_endpoint.py          # Test authentication
â”‚   â”œâ”€â”€ test_auth_endpoint_urllib.py   # Auth test (urllib)
â”‚   â”œâ”€â”€ test_dual_models.py            # Test dual model loading
â”‚   â”œâ”€â”€ test_ollama.py                 # Test Ollama connection
â”‚   â”œâ”€â”€ test_timeout.py                # Test timeout handling
â”‚   â””â”€â”€ test_timeout2.py               # Additional timeout tests
â”‚
â”œâ”€â”€ ğŸ”™ backend/                        # Backend API & Services
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“„ Core Backend Files
â”‚   â”‚   â”œâ”€â”€ __init__.py                # Package initialization
â”‚   â”‚   â”œâ”€â”€ api.py                     # Main FastAPI application (60KB)
â”‚   â”‚   â”œâ”€â”€ auth.py                    # User authentication & session management
â”‚   â”‚   â”œâ”€â”€ auth_endpoints.py          # Authentication API routes
â”‚   â”‚   â”œâ”€â”€ ingestion.py               # Document processing pipeline (27KB)
â”‚   â”‚   â”œâ”€â”€ opensearch_client.py       # Vector search client (14KB)
â”‚   â”‚   â”œâ”€â”€ reranker.py                # Cross-encoder reranking (7.5KB)
â”‚   â”‚   â”œâ”€â”€ watcher.py                 # File system monitoring (8.7KB)
â”‚   â”‚   â”œâ”€â”€ watcher_endpoints.py       # File watcher API routes
â”‚   â”‚   â”œâ”€â”€ upload_endpoints.py        # File upload handling
â”‚   â”‚   â”œâ”€â”€ index_endpoint.py          # Document indexing routes
â”‚   â”‚   â”œâ”€â”€ a2a_agent.py               # Agent-to-Agent communication (22KB)
â”‚   â”‚   â”œâ”€â”€ mcp_tools.py               # MCP server tools (7.9KB)
â”‚   â”‚   â””â”€â”€ streaming_steps.py         # SSE streaming utilities
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ¤– agents/                     # AI Agent System
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ query_classifier.py        # Classifies user intent (16.6KB)
â”‚   â”‚   â”œâ”€â”€ analysis_agent.py          # Document analysis & summarization (9.9KB)
â”‚   â”‚   â”œâ”€â”€ clarification_agent.py     # Asks clarifying questions (9.2KB)
â”‚   â”‚   â”œâ”€â”€ critic_agent.py            # Quality control & validation (8.7KB)
â”‚   â”‚   â”œâ”€â”€ explanation_agent.py       # Explains search results (4.1KB)
â”‚   â”‚   â””â”€â”€ summarization_agent.py     # Document summarization (4.6KB)
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ§  memory/                     # Memory System
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ memory_manager.py          # Central memory coordinator (11KB)
â”‚   â”‚   â”œâ”€â”€ conversation_manager.py    # Conversation history (12.5KB)
â”‚   â”‚   â”œâ”€â”€ session_memory.py          # Short-term session memory (8.9KB)
â”‚   â”‚   â”œâ”€â”€ user_profile.py            # Long-term user profiles (12.1KB)
â”‚   â”‚   â””â”€â”€ procedural_memory.py       # Learning & patterns (8.2KB)
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ¯ orchestration/              # Agent Coordination
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ orchestrator.py            # Main agent orchestrator (19.7KB)
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ”§ utils/                      # Utility Functions
â”‚       â”œâ”€â”€ llm_utils.py               # LLM interaction utilities (10KB)
â”‚       â””â”€â”€ model_manager.py           # Model loading & management (7.1KB)
â”‚
â”œâ”€â”€ ğŸ’» frontend/                       # React Frontend
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“¦ Configuration
â”‚   â”‚   â”œâ”€â”€ package.json               # NPM dependencies
â”‚   â”‚   â”œâ”€â”€ package-lock.json          # Dependency lockfile
â”‚   â”‚   â”œâ”€â”€ vite.config.js             # Vite build configuration
â”‚   â”‚   â”œâ”€â”€ index.html                 # Main HTML entry point
â”‚   â”‚   â”œâ”€â”€ setup.bat                  # Frontend setup script
â”‚   â”‚   â””â”€â”€ README.md                  # Frontend documentation
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ src/                        # Source Code
â”‚   â”‚   â”œâ”€â”€ main.jsx                   # React entry point
â”‚   â”‚   â”œâ”€â”€ App.jsx                    # Root component (2.9KB)
â”‚   â”‚   â”œâ”€â”€ index.css                  # Global styles
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ§© components/             # React Components
â”‚   â”‚   â”‚   â”œâ”€â”€ OnboardingWizard.jsx   # First-time setup (18.3KB)
â”‚   â”‚   â”‚   â”œâ”€â”€ OnboardingWizard.css
â”‚   â”‚   â”‚   â”œâ”€â”€ OnboardingWizard-watcher.css
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatInterface.jsx      # Main chat UI (13.2KB)
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatInterface.css
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatInterface-buttons.css
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatSidebar.jsx        # Conversation sidebar (5.8KB)
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatSidebar.css
â”‚   â”‚   â”‚   â”œâ”€â”€ DocumentSelector.jsx   # Attach documents (8.7KB)
â”‚   â”‚   â”‚   â”œâ”€â”€ DocumentSelector.css
â”‚   â”‚   â”‚   â”œâ”€â”€ SettingsPanel.jsx      # System settings (18.3KB)
â”‚   â”‚   â”‚   â”œâ”€â”€ SettingsPanel.css
â”‚   â”‚   â”‚   â”œâ”€â”€ SettingsPanel-additions.css
â”‚   â”‚   â”‚   â”œâ”€â”€ IndexingProgress.jsx   # Real-time indexing indicator (4.4KB)
â”‚   â”‚   â”‚   â”œâ”€â”€ IndexingProgress.css
â”‚   â”‚   â”‚   â”œâ”€â”€ LoginSettings.jsx      # Login/auth controls (6.8KB)
â”‚   â”‚   â”‚   â”œâ”€â”€ LoginSettings.css
â”‚   â”‚   â”‚   â””â”€â”€ index.js               # Component exports
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸª hooks/                  # Custom React Hooks
â”‚   â”‚   â”‚   â””â”€â”€ (React custom hooks)
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ ğŸ¨ styles/                 # Additional Stylesheets
â”‚   â”‚       â””â”€â”€ (Additional CSS files)
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“„ components/                 # Standalone Components
â”‚       â””â”€â”€ ConversationExporter.jsx   # Export conversation feature
â”‚
â””â”€â”€ ğŸ“‚ Other Files
    â”œâ”€â”€ frontend_sse_example.jsx       # SSE implementation example
    â”œâ”€â”€ frontend_sse_vanilla.js        # Vanilla JS SSE example
    â””â”€â”€ chat.html                      # Standalone chat interface
```

---

## ğŸ—ï¸ Architecture Overview

### System Layers

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         FRONTEND (React + Vite)                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ OnboardingWizard â†’ ChatInterface â†’ Settings  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ HTTP REST + SSE
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         BACKEND (FastAPI)                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚      Enhanced Orchestrator                  â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚    â”‚
â”‚  â”‚  â”‚ Query    â”‚ Search   â”‚ Analysis     â”‚    â”‚    â”‚
â”‚  â”‚  â”‚Classifierâ”‚  Agent   â”‚  Agent       â”‚    â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚      Memory System (Session + User)         â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚      Ingestion Pipeline                     â”‚    â”‚
â”‚  â”‚  File â†’ Extract â†’ Chunk â†’ Embed â†’ Index    â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚          â”‚          â”‚          â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â” â”Œâ”€â”€â”€â”´â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”´â”€â”€â”€â”€â” â”Œâ”€â”€â”´â”€â”€â”€â”€â”€â”
â”‚OpenSearchâ”‚ â”‚ Ollama â”‚ â”‚ SQLite â”‚ â”‚Watchdogâ”‚
â”‚ Vector   â”‚ â”‚  LLM   â”‚ â”‚Memory/ â”‚ â”‚  File  â”‚
â”‚   DB     â”‚ â”‚Embedderâ”‚ â”‚ Users  â”‚ â”‚Monitor â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âš™ï¸ How The System Works

### 1ï¸âƒ£ User Onboarding Flow

```
User opens app (localhost:5173)
  â†“
Check if logged in (localStorage.session_token)
  â†“
NO â†’ Show OnboardingWizard
  â”œâ”€ Step 1: Choose Sign Up / Sign In
  â”œâ”€ Step 2: Enter credentials
  â”‚   POST /auth/register or /auth/login
  â”‚   Returns session_token
  â”œâ”€ Step 3: Index documents
  â”‚   Option A: Enter folder path â†’ POST /index/directory
  â”‚   Option B: Upload files â†’ POST /upload-batch
  â”‚   Returns task_id
  â”œâ”€ Step 4: Enable file watcher (optional)
  â”‚   POST /watcher/enable
  â””â”€ Complete â†’ Save session_token to localStorage
  â†“
YES â†’ Show ChatInterface
```

### 2ï¸âƒ£ Document Indexing Flow

```
User provides documents (path or upload)
  â†“
Backend receives files
  â†“
For each file:
  â”œâ”€ 1. Detect file type (PDF, DOCX, XLSX, image, text)
  â”œâ”€ 2. Extract text
  â”‚   PDF â†’ PyPDF2 + pdfplumber
  â”‚   DOCX â†’ python-docx
  â”‚   XLSX/CSV â†’ pandas
  â”‚   Image â†’ pytesseract OCR
  â”‚   Text â†’ direct read
  â”œâ”€ 3. Split into chunks (800 tokens, 200 overlap)
  â”œâ”€ 4. Generate embeddings (nomic-embed-text via Ollama)
  â”‚   Creates 768-dimensional vectors
  â”œâ”€ 5. Index to OpenSearch
  â”‚   Vector field (knn_vector) + BM25 text field
  â”‚   Store metadata: filename, path, user_id, timestamp
  â””â”€ 6. Update progress status (task_id)
  â†“
Return task_id
  â†“
Frontend polls /index/status/{task_id} every 1 second
  â†“
Display real-time progress (IndexingProgress component)
```

### 3ï¸âƒ£ Search & Conversation Flow

```
User types query in ChatInterface
  â†“
POST /search/enhanced
  â†“
Orchestrator receives query
  â†“
1. QUERY CLASSIFICATION (query_classifier.py)
   - Analyze intent
   - Categories: SEARCH, ANALYSIS, CLARIFICATION, GENERAL
   - Confidence scoring
  â†“
2. AGENT ROUTING
   â”œâ”€ SEARCH â†’ Search Agent
   â”‚   â”œâ”€ Generate query embedding
   â”‚   â”œâ”€ Vector search (cosine similarity, top 50)
   â”‚   â”œâ”€ BM25 keyword search (top 50)
   â”‚   â”œâ”€ Hybrid fusion (RRF - Reciprocal Rank Fusion)
   â”‚   â””â”€ Rerank with cross-encoder (top 5)
   â”‚
   â”œâ”€ ANALYSIS â†’ Analysis Agent
   â”‚   â”œâ”€ Summarize documents
   â”‚   â”œâ”€ Extract key points
   â”‚   â””â”€ Topic classification
   â”‚
   â”œâ”€ CLARIFICATION â†’ Clarification Agent
   â”‚   â”œâ”€ Detect ambiguity
   â”‚   â””â”€ Generate clarifying questions
   â”‚
   â””â”€ GENERAL â†’ Direct LLM response
  â†“
3. MEMORY INTEGRATION
   â”œâ”€ Load conversation history (last 10 turns)
   â”œâ”€ Check attached documents
   â”œâ”€ Load user profile preferences
   â””â”€ Update session memory
  â†“
4. RESPONSE GENERATION
   â”œâ”€ Combine agent outputs
   â”œâ”€ Format with citations
   â”œâ”€ Stream via SSE (thinking steps)
   â””â”€ Save to conversation history
  â†“
5. FRONTEND DISPLAY
   â”œâ”€ Show search results with metadata
   â”œâ”€ Display LLM response
   â”œâ”€ Enable "Attach" and "Open" buttons
   â””â”€ Update conversation sidebar
```

### 4ï¸âƒ£ File Watcher Flow

```
User enables file watcher
  â†“
POST /watcher/enable with directory path
  â†“
Backend starts Watchdog observer
  â†“
Monitor file system events:
  â”œâ”€ on_created â†’ New file added
  â”œâ”€ on_modified â†’ File changed
  â”œâ”€ on_deleted â†’ File removed (delete from index)
  â””â”€ on_moved â†’ File renamed (update index)
  â†“
Debounce events (3 seconds)
  â†“
Auto-index new/modified files
  â†“
Update user's document index in background
```

---

## ğŸ”™ Backend Components

### Core Backend Files

| File | Purpose | Key Functions |
|------|---------|---------------|
| `api.py` | Main FastAPI app | All REST endpoints, CORS, SSE streaming, startup hooks |
| `auth.py` | Authentication | `register_user()`, `authenticate()`, `verify_session()` |
| `auth_endpoints.py` | Auth routes | `/auth/register`, `/auth/login`, `/auth/verify` |
| `ingestion.py` | Document processing | `process_file()`, `extract_text()`, `chunk_text()`, `embed()` |
| `opensearch_client.py` | Vector search | `create_index()`, `search()`, `hybrid_search()`, `delete()` |
| `reranker.py` | Result reranking | Cross-encoder scoring, relevance boosting |
| `watcher.py` | File monitoring | Watchdog integration, debouncing, event handling |
| `upload_endpoints.py` | File uploads | `/upload-batch` multipart handling |
| `index_endpoint.py` | Indexing routes | `/index/directory`, `/index/status/{task_id}` |

### Agent System (`backend/agents/`)

| Agent | File | Purpose | Input | Output |
|-------|------|---------|-------|--------|
| **Query Classifier** | `query_classifier.py` | Determines user intent | Query text | Intent category + confidence |
| **Analysis Agent** | `analysis_agent.py` | Document analysis | Documents | Summary, key points, entities |
| **Clarification Agent** | `clarification_agent.py` | Handles ambiguity | Ambiguous query | Clarifying questions |
| **Critic Agent** | `critic_agent.py` | Quality control | Agent responses | Quality score, improvements |
| **Explanation Agent** | `explanation_agent.py` | Explains results | Search results | User-friendly explanations |
| **Summarization Agent** | `summarization_agent.py` | Summarizes docs | Long documents | Concise summaries |

### Memory System (`backend/memory/`)

| Component | File | Storage | Purpose |
|-----------|------|---------|---------|
| **Memory Manager** | `memory_manager.py` | Coordinator | Central hub for all memory operations |
| **Session Memory** | `session_memory.py` | Redis/In-memory | Short-term conversation context (last 10 turns) |
| **User Profile** | `user_profile.py` | SQLite | Long-term preferences, search history |
| **Procedural Memory** | `procedural_memory.py` | Cache | Learning patterns, common queries |
| **Conversation Manager** | `conversation_manager.py` | SQLite | Full conversation history persistence |

### Orchestration (`backend/orchestration/`)

| Component | Purpose |
|-----------|---------|
| `orchestrator.py` | Routes queries to appropriate agents, coordinates multi-agent workflows, synthesizes responses |

### Utilities (`backend/utils/`)

| File | Purpose |
|------|---------|
| `llm_utils.py` | Helper functions for Ollama API calls, prompt formatting, streaming |
| `model_manager.py` | Dynamic model loading/unloading, GPU management |

---

## ğŸ’» Frontend Components

### React Components (`frontend/src/components/`)

| Component | File | Purpose | Key Features |
|-----------|------|---------|--------------|
| **OnboardingWizard** | `OnboardingWizard.jsx` (18KB) | First-time setup | Sign up/in, document indexing, file watcher setup |
| **ChatInterface** | `ChatInterface.jsx` (13KB) | Main chat UI | Semantic search, streaming responses, result display |
| **ChatSidebar** | `ChatSidebar.jsx` (5.8KB) | Conversation list | Switch conversations, create new, delete |
| **DocumentSelector** | `DocumentSelector.jsx` (8.7KB) | Attach documents | Select docs for focused queries, visual doc list |
| **SettingsPanel** | `SettingsPanel.jsx` (18KB) | System management | Indexing tab, system health, settings |
| **IndexingProgress** | `IndexingProgress.jsx` (4.4KB) | Progress indicator | Non-blocking, real-time polling, collapsible |
| **LoginSettings** | `LoginSettings.jsx` (6.8KB) | Auth controls | Password change, logout |

### Component Hierarchy

```
App.jsx (root)
  â”œâ”€ indexingTaskId (global state)
  â”œâ”€ session_token (localStorage)
  â”‚
  â”œâ”€â”€â”€ OnboardingWizard (if !logged in)
  â”‚      â”œâ”€ Step 1: Sign Up / Sign In
  â”‚      â”œâ”€ Step 2: Credentials
  â”‚      â”œâ”€ Step 3: Index Documents
  â”‚      â””â”€ Step 4: File Watcher
  â”‚
  â””â”€â”€â”€ ChatInterface (if logged in)
         â”œâ”€ ChatSidebar (left panel)
         â”œâ”€ Search Input + Results (center)
         â”œâ”€ DocumentSelector (attached docs)
         â”œâ”€ SettingsPanel (gear icon)
         â””â”€ IndexingProgress (bottom-right if taskId exists)
```

---

## ğŸ”„ Data Flow

### Authentication Data Flow

```
Frontend                Backend               Storage
â”€â”€â”€â”€â”€â”€â”€â”€                â”€â”€â”€â”€â”€â”€â”€               â”€â”€â”€â”€â”€â”€â”€
[Sign Up Form]
  user_id + password
      â”‚
      â”œâ”€â”€POST /auth/registerâ”€â”€â†’ auth_endpoints.py
      â”‚                              â”‚
      â”‚                              â”œâ”€ Hash password (SHA-256)
      â”‚                              â”œâ”€ Generate session token
      â”‚                              â””â”€ Save to locallens_users.json
      â”‚                              
      â†â”€â”€{session_token}â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â””â”€ Save to localStorage
```

### Search Data Flow

```
Frontend                 Backend                    OpenSearch      Ollama
â”€â”€â”€â”€â”€â”€â”€â”€                 â”€â”€â”€â”€â”€â”€â”€                    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€      â”€â”€â”€â”€â”€â”€
[Search Query]
  "find my resume"
      â”‚
      â”œâ”€â”€POST /search/enhancedâ”€â”€â†’ api.py
      â”‚                             â”‚
      â”‚                             â”œâ”€ orchestrator.py
      â”‚                             â”‚    â”œâ”€ query_classifier.py
      â”‚                             â”‚    â””â”€ Determine: SEARCH
      â”‚                             â”‚
      â”‚                             â”œâ”€ Generate embeddingâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ nomic-embed-text
      â”‚                             â”‚                                     â”‚
      â”‚                             â”‚    â†â”€â”€[768-dim vector]â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚                             â”‚
      â”‚                             â”œâ”€ Vector searchâ”€â”€â”€â”€â”€â”€â”€â”€â†’ OpenSearch
      â”‚                             â”‚                            (cosine similarity)
      â”‚                             â”‚    â†â”€â”€[top 50 results]â”€â”€â”€â”€â”€â”˜
      â”‚                             â”‚
      â”‚                             â”œâ”€ BM25 searchâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ OpenSearch
      â”‚                             â”‚                            (keyword)
      â”‚                             â”‚    â†â”€â”€[top 50 results]â”€â”€â”€â”€â”€â”˜
      â”‚                             â”‚
      â”‚                             â”œâ”€ Hybrid fusion (RRF)
      â”‚                             â”‚
      â”‚                             â”œâ”€ Rerankâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ cross-encoder
      â”‚                             â”‚                                     â”‚
      â”‚                             â”‚    â†â”€â”€[top 5 results]â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚                             â”‚
      â”‚                             â””â”€ Format response
      â”‚
      â†â”€â”€{results + metadata}â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â””â”€ Display in ChatInterface
```

### Indexing Data Flow

```
Frontend                 Backend                    OpenSearch      Ollama
â”€â”€â”€â”€â”€â”€â”€â”€                 â”€â”€â”€â”€â”€â”€â”€                    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€      â”€â”€â”€â”€â”€â”€
[Upload Files]
  file1.pdf, file2.docx
      â”‚
      â”œâ”€â”€POST /upload-batch (multipart)â”€â”€â†’ upload_endpoints.py
      â”‚                                         â”‚
      â”‚                                         â”œâ”€ Save to temp dir
      â”‚                                         â”œâ”€ Create task_id
      â”‚                                         â””â”€ Start ingestion
      â”‚
      â†â”€â”€{task_id}â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â”œâ”€ Poll /index/status/{task_id} (1s interval)
      â”‚
      â”‚                                    ingestion.py
      â”‚                                         â”‚
      â”‚                                    For each file:
      â”‚                                         â”œâ”€ Extract text
      â”‚                                         â”œâ”€ Split into chunks (800 tokens)
      â”‚                                         â”œâ”€ Generate embeddingsâ”€â”€â”€â†’ nomic-embed-text
      â”‚                                         â”‚                              â”‚
      â”‚                                         â”‚   â†â”€â”€[vectors[]]â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚                                         â”‚
      â”‚                                         â””â”€ Index documentsâ”€â”€â”€â”€â†’ OpenSearch
      â”‚                                                                     â”‚
      â”‚                                                  â†â”€â”€{success}â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â†â”€â”€{processed: 2, total: 2}â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âš™ï¸ Configuration

### `config.yaml` Structure

```yaml
# LLM Models
ollama:
  base_url: "http://localhost:11434"
  text_model: "qwen2.5:7b"
  vision_model: "qwen2.5vl:latest"

# Vector Database
opensearch:
  host: "localhost"
  port: 9200
  index_name: "locallens_index"

# Embedding Model
models:
  embedding:
    name: "nomic-embed-text"
    dimension: 768

# Search Settings
search:
  hybrid: true
  vector_weight: 0.7
  bm25_weight: 0.3
  recall_top_k: 50
  rerank_top_k: 5

# Agents
agents:
  classifier: enabled
  clarification: enabled
  analysis: enabled
  summarization: enabled
  critic: enabled

# Memory System
memory:
  session:
    backend: "redis"  # or "memory"
    window_size: 10
  user_profile:
    backend: "sqlite"
    database_url: "sqlite+aiosqlite:///locallens_memory.db"
  procedural:
    enable_learning: true

# Ingestion
ingestion:
  chunk_size: 800
  chunk_overlap: 200
  max_workers: 1

# File Watcher
watcher:
  debounce_seconds: 3
  supported_extensions: [".pdf", ".docx", ".txt", ".xlsx", ".png", ".jpg"]
```

---

## ğŸ—„ï¸ Database Schema

### SQLite Databases

#### **locallens_conversations.db**

```sql
-- Conversations table
CREATE TABLE conversations (
    conversation_id TEXT PRIMARY KEY,
    user_id TEXT NOT NULL,
    title TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Messages table
CREATE TABLE messages (
    message_id TEXT PRIMARY KEY,
    conversation_id TEXT NOT NULL,
    role TEXT NOT NULL,  -- 'user' or 'assistant'
    content TEXT NOT NULL,
    results JSON,        -- Search results if applicable
    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (conversation_id) REFERENCES conversations(conversation_id)
);

-- Attached documents
CREATE TABLE attached_documents (
    conversation_id TEXT NOT NULL,
    document_id TEXT NOT NULL,
    filename TEXT,
    added_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    PRIMARY KEY (conversation_id, document_id)
);
```

#### **locallens_memory.db**

```sql
-- User profiles
CREATE TABLE users (
    user_id TEXT PRIMARY KEY,
    profile JSON,        -- Preferences, settings
    search_history JSON, -- Recent searches
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Session memory
CREATE TABLE sessions (
    session_id TEXT PRIMARY KEY,
    user_id TEXT NOT NULL,
    context JSON,        -- Conversation context
    expires_at TIMESTAMP,
    FOREIGN KEY (user_id) REFERENCES users(user_id)
);

-- Procedural memory (learning)
CREATE TABLE patterns (
    pattern_id TEXT PRIMARY KEY,
    user_id TEXT NOT NULL,
    query_pattern TEXT,
    frequency INTEGER DEFAULT 1,
    last_used TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

### OpenSearch Index Schema

```json
{
  "mappings": {
    "properties": {
      "text": {
        "type": "text",
        "analyzer": "standard"
      },
      "embedding": {
        "type": "knn_vector",
        "dimension": 768,
        "method": {
          "name": "hnsw",
          "space_type": "l2",
          "engine": "nmslib",
          "parameters": {
            "ef_construction": 128,
            "m": 24
          }
        }
      },
      "filename": {"type": "keyword"},
      "file_path": {"type": "keyword"},
      "file_type": {"type": "keyword"},
      "file_size": {"type": "long"},
      "user_id": {"type": "keyword"},
      "chunk_index": {"type": "integer"},
      "timestamp": {"type": "date"},
      "metadata": {"type": "object"}
    }
  }
}
```

### User Authentication Storage (`locallens_users.json`)

```json
{
  "users": {
    "john_doe": {
      "password_hash": "sha256_hash_here",
      "created_at": "2025-12-01T10:30:00Z",
      "sessions": {
        "session_token_abc123": {
          "created_at": "2025-12-03T03:00:00Z",
          "expires_at": "2025-12-04T03:00:00Z"
        }
      }
    }
  }
}
```

---

## ğŸ”§ Development Workflow

### Starting the Application

#### Prerequisites
1. **OpenSearch** running on port 9200
2. **Ollama** running on port 11434
3. Models pulled: `nomic-embed-text`, `qwen2.5:7b`

#### Option 1: Run Scripts
```bash
# Windows
run.bat

# Linux/Mac
chmod +x run.sh
./run.sh
```

#### Option 2: Manual Start
```bash
# Terminal 1: Backend
cd LocaLense_V2
python -m backend.api

# Terminal 2: Frontend
cd frontend
npm run dev
```

#### Option 3: Legacy Entry Point
```bash
python app.py
```

### API Endpoints

#### Authentication
- `POST /auth/register` - Create new user
- `POST /auth/login` - Login and get session token
- `GET /auth/verify` - Verify session token

#### Indexing
- `POST /index/directory` - Index folder path
- `POST /upload-batch` - Upload files
- `GET /index/status/{task_id}` - Check indexing progress

#### Search
- `POST /search/enhanced` - Semantic search
- `GET /search/enhanced/stream/{session_id}` - SSE stream

#### File Watcher
- `POST /watcher/enable` - Enable file monitoring
- `GET /watcher/status` - Check watcher status
- `POST /watcher/disable` - Stop monitoring

#### Conversations
- `GET /conversations` - List all conversations
- `POST /conversations` - Create new conversation
- `GET /conversations/{id}` - Get conversation details
- `DELETE /conversations/{id}` - Delete conversation

### Development Commands

```bash
# Install Python dependencies
pip install -r requirements.txt

# Install frontend dependencies
cd frontend
npm install

# Initialize memory database
python init_memory.py

# Delete OpenSearch index (reset)
python delete_index.py

# Test Ollama connection
python test_ollama.py

# Test authentication
python test_auth_endpoint.py
```

---

## ğŸ¯ Key Workflows

### 1. Adding a New Agent

1. Create file in `backend/agents/new_agent.py`
2. Implement agent class with `process()` method
3. Register in `backend/agents/__init__.py`
4. Add configuration in `config.yaml` under `agents:`
5. Update orchestrator routing in `backend/orchestration/orchestrator.py`

### 2. Adding a New API Endpoint

1. Add route in `backend/api.py` or create new endpoint file
2. Import endpoint file in `backend/api.py`
3. Add authentication if needed (`verify_session()`)
4. Update frontend API calls in respective components

### 3. Modifying Search Algorithm

1. Edit `backend/opensearch_client.py` for vector search logic
2. Edit `backend/reranker.py` for reranking algorithm
3. Adjust weights in `config.yaml` under `search:`
4. Test with `test_dual_models.py` or similar

---

## ğŸ“Š System Flow Summary

```
USER JOURNEY
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

1. First Visit â†’ OnboardingWizard
   â”œâ”€ Sign Up/In
   â”œâ”€ Index Documents
   â””â”€ Enable File Watcher (optional)

2. Main Interface â†’ ChatInterface
   â”œâ”€ Type query
   â”œâ”€ Orchestrator classifies intent
   â”œâ”€ Search Agent finds documents
   â”œâ”€ Memory system adds context
   â”œâ”€ LLM generates response
   â””â”€ Results displayed with citations

3. Document Management
   â”œâ”€ View search results
   â”œâ”€ Attach documents to conversation
   â”œâ”€ Open files
   â””â”€ Continue focused queries

4. Settings â†’ SettingsPanel
   â”œâ”€ Index more documents
   â”œâ”€ Check system health
   â””â”€ Manage file watcher

5. Background Processes
   â”œâ”€ File watcher auto-indexes new files
   â”œâ”€ Memory system learns patterns
   â””â”€ Session cleanup
```

---

## ğŸš€ Future Enhancements

### Planned Features (from TODO)
- âœ¨ In-document chatting (direct Q&A with specific PDFs)
- âœ¨ Export features (conversations, search results)
- âœ¨ Analytics dashboard (search stats, popular docs)
- âœ¨ Advanced filters (date range, file type, size)
- âœ¨ Multi-language support
- âœ¨ Cross-document synthesis
- âœ¨ Plugin system
- âœ¨ Enterprise features (RBAC, SSO, audit logging)

---

## ğŸ“š Related Documentation

- **[README.md](README.md)** - Main project overview
- **[ARCHITECTURE.md](ARCHITECTURE.md)** - Detailed technical architecture
- **[QUICKSTART.md](QUICKSTART.md)** - Quick setup guide
- **[frontend/README.md](frontend/README.md)** - Frontend-specific docs

---

## ğŸ” Quick Reference

### Port Map
- **Frontend:** `localhost:5173` (Vite dev server)
- **Backend API:** `localhost:8000` (FastAPI)
- **OpenSearch:** `localhost:9200`
- **Ollama:** `localhost:11434`
- **MCP Server:** `localhost:8001` (optional)

### File Size Summary
- **Backend API:** 60KB (`api.py`)
- **Ingestion Pipeline:** 27KB (`ingestion.py`)
- **Agent Orchestrator:** 19.7KB (`orchestrator.py`)
- **Settings Panel:** 18.3KB (`SettingsPanel.jsx`)
- **Onboarding Wizard:** 18.3KB (`OnboardingWizard.jsx`)

### Total Project Statistics
- **Backend Files:** ~58 Python files
- **Frontend Files:** ~34 JavaScript/JSX files
- **Configuration Files:** YAML, JSON, BAT, SH
- **Documentation:** 5 markdown files
- **Lines of Code:** ~15,000+ (estimated)

---

**Last Updated:** December 3, 2025  
**Version:** 2.0  
**Status:** Active Development  
**License:** MIT

**Made with â¤ï¸ using AI-powered semantic search**
